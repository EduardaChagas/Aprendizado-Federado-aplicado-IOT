{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bj3F1nTZj1ho"
   },
   "source": [
    "# Hands On - Aprendizado Federado aplicado à Internet das Coisas\n",
    "\n",
    "**Notebook 2**: Criação de clientes no ambiente federado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJPTVnswkMdN"
   },
   "source": [
    "O reconhecimento da atividade humana é uma área de pesquisa ativa e que possui um enorme potencial de benefício com o uso de aprendizado federado (FL), já que tais dados são normalmente privados e possuem informações sensíveis sobre os usuários.\n",
    "Além disso, com FL também podemos desenvolver um modelo conjunto que consiga capturar a diversidade dos dados, algo que é extremamente difícil de ser coletado de forma individual.\n",
    "\n",
    "Sob esse contexto, nesse tutorial vamos aprender como definir clientes para o treinamento federado de uma rede neural para auxilar no reconhecimento de atividades humanas (*Human Activity Recognition* - HAR) usando o framework de aprendizado federado\n",
    "Flower em conjunto com a biblioteca de deep learning Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hX7rxsAk8CT"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Os dados serão particionados horizontalmente, assim os subconjuntos de treinamento e teste irão ser divididos em mini-batches (pequenos lotes) com base no número total de clientes.\n",
    "\n",
    "Para isso, aplicaremos uma função auxiliar para carregar os dados e definir os conjuntos de treinamento e teste.\n",
    "Nessa função, precisaremos dos seguintes parâmetros: \n",
    "\n",
    "* **data root (str)**: Diretório onde os datasets finais serão armazenados. \n",
    "\n",
    "* **train batch size (int)**: Tamanho do mini-batch usado nos dados de treinamento.\n",
    "\n",
    "* **test batch size (int)**: Tamanho do mini-batch usado nos dados de teste. \n",
    "\n",
    "* **id (int)**: Client ID usado para selecionar uma partição específica. \n",
    "\n",
    "* **nb clients (int)**: Número total de clientes usados no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVQzVKL2r67J",
    "outputId": "67066d3f-f7bb-412c-e76b-091aea68ff3c"
   },
   "outputs": [],
   "source": [
    "#Carregando os dados\n",
    "import flwr as fl\n",
    "import torch\n",
    "import aux\n",
    "\n",
    "DATA_ROOT = \"./data/pml-training.csv\"\n",
    "\n",
    "server_address = \"[::]:8081\"\n",
    "cid = 1\n",
    "nb_clients = 2\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Load data\n",
    "train_loader, test_loader = aux.load_data(\n",
    "        data_root = DATA_ROOT,\n",
    "        train_batch_size = train_batch_size,\n",
    "        test_batch_size = test_batch_size,\n",
    "        cid = cid,\n",
    "        nb_clients = nb_clients + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arvhg44xrwWm"
   },
   "source": [
    "### Rede Neural\n",
    "\n",
    "Atualmente o modelo de classificação mais adequado e vantajoso para a modelagem de um ambiente federado são as redes neurais.\n",
    "Definimos essa configuração de arquitetura por meio da criação de uma classe em Pytorch denominada **HARmodel** presente no arquivo auxiliar *aux.py* adicionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-glqWQnYsGt3"
   },
   "source": [
    "### Cliente Flower\n",
    "\n",
    "O próximo passo é definir a alocação dos dispositivos no ambiente federado. \n",
    "\n",
    "Quando o servidor seleciona um dispositivo específico do ambiente federado para realizar um treinamento, ele envia as instruções pela rede, por meio de uma interface chamada **Client**.\n",
    "Assim, o cliente recebe as instruções do servidor e chama um dos métodos desta classe para executar seu código (ou seja, para treinar a sua rede neural local). \n",
    "\n",
    "O framework Flower fornece uma classe chamada *NumPyClient*, que torna mais fácil implementar a interface do cliente quando utilizamos PyTorch. \n",
    "Quando implementamos um NumPyClient devemos definir os seguintes métodos: \n",
    "\n",
    "* **get_parameters**: retorna o peso do modelo\n",
    "como uma lista de ndarrays \n",
    "\n",
    "* **set_parameters** (opcional): atualiza os pesos do modelo\n",
    "local com os parâmetros recebidos do servidor \n",
    "\n",
    "* **fit**: define os pesos do modelo local, treina o modelo localmente e recebe o update dos pesos locais \n",
    "\n",
    "* **evaluate**: define como o modelo local será testado. \n",
    "\n",
    "Abaixo mostramos como a classe Client foi implementada\n",
    "para o caso de estudo apresentado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MEUIciNJ69re"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate client\n",
    "client = aux.FlowerClient(\n",
    "    cid = cid,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    epochs = epochs,\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNxtUr3s67hn"
   },
   "source": [
    "### Inicializando o cliente\n",
    "\n",
    "O flower nos fornece a possibilidade de rodar o servidor e o cliente na mesma máquina, configurando o endereço do servidor como \"[::]: 8080\". \n",
    "Porém, se quisermos implementar uma aplicação realmente federada com o servidor e clientes em execução em diferentes máquinas, precisaremos apenas alterar o server address para o respectivo endereço da máquina do cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CD9ie8II7QHB",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2021-08-19 22:31:09,619 | connection.py:36 | ChannelConnectivity.IDLE\n",
      "DEBUG flower 2021-08-19 22:31:09,621 | connection.py:36 | ChannelConnectivity.READY\n",
      "INFO flower 2021-08-19 22:31:09,622 | app.py:61 | Opened (insecure) gRPC connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 10 epoch(s) w/ 103 mini-batches each\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 1.596585, Acc: 0.221749 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 1.424146, Acc: 0.291193 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 1.340835, Acc: 0.347538 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 1.329292, Acc: 0.389047 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 1.259240, Acc: 0.431976 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 1.272115, Acc: 0.458333 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 1.290238, Acc: 0.487689 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.295281, Acc: 0.509785 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 1.069018, Acc: 0.523201 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each50, Acc: 0.536143 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 1.174034, Acc: 0.508049 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 1.116313, Acc: 0.527778 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.999377, Acc: 0.538510 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 1.014143, Acc: 0.558870 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 1.062258, Acc: 0.572601 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 1.411789, Acc: 0.575442 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.810705, Acc: 0.580808 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.113037, Acc: 0.589646 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.983736, Acc: 0.602273 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each82, Acc: 0.602115 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 1.050986, Acc: 0.591540 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.984716, Acc: 0.603378 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 1.128920, Acc: 0.610953 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 1.012483, Acc: 0.618371 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.890974, Acc: 0.623106 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.881757, Acc: 0.623737 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.889666, Acc: 0.637153 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.036112, Acc: 0.628314 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 1.177366, Acc: 0.633838 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each65, Acc: 0.632734 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.833697, Acc: 0.637468 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 1.056082, Acc: 0.646149 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 1.158078, Acc: 0.647727 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.956637, Acc: 0.648043 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.919814, Acc: 0.654356 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 1.002852, Acc: 0.655461 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.940354, Acc: 0.660511 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.067120, Acc: 0.663352 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.971590, Acc: 0.662090 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each03, Acc: 0.667140 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.831428, Acc: 0.663826 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.751292, Acc: 0.664457 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.831113, Acc: 0.668876 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 1.045704, Acc: 0.672506 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.947567, Acc: 0.674242 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.671743, Acc: 0.679766 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.778177, Acc: 0.670455 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.135973, Acc: 0.677083 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.949835, Acc: 0.679924 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each71, Acc: 0.687500 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.900232, Acc: 0.680240 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.870391, Acc: 0.682134 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.777826, Acc: 0.690499 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.718067, Acc: 0.685764 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.860861, Acc: 0.681187 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.948297, Acc: 0.701389 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.803200, Acc: 0.694129 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 0.829474, Acc: 0.693813 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.861357, Acc: 0.685922 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each93, Acc: 0.699495 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.861112, Acc: 0.695391 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.678459, Acc: 0.698390 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.954704, Acc: 0.698706 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.990921, Acc: 0.708807 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.755861, Acc: 0.700442 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.836829, Acc: 0.706439 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.993197, Acc: 0.707544 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 0.350469, Acc: 0.706755 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.753746, Acc: 0.704230 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each17, Acc: 0.710701 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.803239, Acc: 0.699811 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.776836, Acc: 0.715593 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.708873, Acc: 0.707229 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.821281, Acc: 0.710227 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.698361, Acc: 0.705650 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.749210, Acc: 0.713857 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.902384, Acc: 0.701231 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 0.609983, Acc: 0.706439 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.760222, Acc: 0.715436 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each90, Acc: 0.704861 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.772987, Acc: 0.706755 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.715529, Acc: 0.706755 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.730417, Acc: 0.708333 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.672982, Acc: 0.712753 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.526156, Acc: 0.719223 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 0.828104, Acc: 0.721275 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.861199, Acc: 0.718592 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 0.896865, Acc: 0.725852 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.659032, Acc: 0.715751 (Cliente 1)\t\t\t\t\n",
      "Training 10 epoch(s) w/ 103 mini-batches each39, Acc: 0.724432 (Cliente 1)\t\t\t\t\n",
      "\n",
      "Train Epoch: 0 [6336/6592 (96%)] Loss: 0.839525, Acc: 0.721433 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 1 [6336/6592 (96%)] Loss: 0.731200, Acc: 0.717330 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 2 [6336/6592 (96%)] Loss: 0.959959, Acc: 0.735953 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 3 [6336/6592 (96%)] Loss: 0.880667, Acc: 0.713068 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 4 [6336/6592 (96%)] Loss: 0.640420, Acc: 0.720013 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 5 [6336/6592 (96%)] Loss: 1.049155, Acc: 0.716856 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 6 [6336/6592 (96%)] Loss: 0.664466, Acc: 0.729798 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 7 [6336/6592 (96%)] Loss: 1.189518, Acc: 0.724432 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 8 [6336/6592 (96%)] Loss: 0.752617, Acc: 0.729640 (Cliente 1)\t\t\t\t\n",
      "Train Epoch: 9 [6336/6592 (96%)] Loss: 0.699003, Acc: 0.724590 (Cliente 1)\t\t\t\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2021-08-19 22:32:15,453 | connection.py:68 | Insecure gRPC channel closed\n",
      "INFO flower 2021-08-19 22:32:15,471 | app.py:72 | Disconnect and shut down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 - Evaluate on 6540 samples: Average loss: 0.0083, Accuracy: 81.27%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Código de instanciação do cliente \n",
    "fl.client.start_client(server_address, client)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2-HAR-client_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
